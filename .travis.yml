language: python
python:
  - "2.6"
  - "2.7"
before_install:
  - sudo apt-get update
  - sudo apt-get install gfortran gcc
  # You may want to periodically update this, although the conda update
  # conda line below will keep everything up-to-date.
  # This saves us some downloading for this version
  - if [[ "$TRAVIS_PYTHON_VERSION" == "2.7" ]]; then
      wget http://repo.continuum.io/miniconda/Miniconda-3.4.2-Linux-x86_64.sh -O miniconda.sh;
    else
      wget http://repo.continuum.io/miniconda/Miniconda3-3.4.2-Linux-x86_64.sh -O miniconda.sh;
    fi
  - bash miniconda.sh -b -p $HOME/miniconda
  - export PATH="$HOME/miniconda/bin:$PATH"
  - conda config --set always_yes yes --set changeps1 no
  - conda update conda
  - conda info -a
install:
  # install deps
  - deps='pip numpy pandas requests nose numpydoc sphinx pep8 numexpr cython'
  - conda create -n test-env --yes $deps "python=$TRAVIS_PYTHON_VERSION"
  - source activate test-env
  - pip install unittest2
  - conda update pandas
  # install our own package into the environment
  - "pip install ."
script:
  # Download spark 1.0.0
  - "wget http://d3kbcqa49mib13.cloudfront.net/spark-1.0.0-bin-hadoop2.tgz"
  - "tar -xvf spark-1.0.0-bin-hadoop2.tgz"
  # Run the tests
  - "export SPARK_HOME=./spark-1.0.0-bin-hadoop2/"
  - "./run-tests"
  - "pep8 sparklingpandas/"