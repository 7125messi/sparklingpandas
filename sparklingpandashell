#!/usr/bin/env bash
if [ -z "$SPARK_HOME" ]; then
   echo "$(tput setaf 1)Error: SPARK_HOME is not set, can not run the sparkling panda shell.$(tput sgr0)"
   exit -1
fi
if [ ! -e "sparkle_dist.zip" ]; then
    zip -r sparkle_dist.zip ./sparklingpandas
fi
if [ ! `ls ./target/scala-2.10/*.jar` ]; then
    echo "Missing our magic jars. Please run ./sbt/sbt clean compile package"
fi
set -x
SPARK_EXECUTOR_MEMORY=${SPARK_EXECUTOR_MEMORY-"2000m"}
JARS=`ls ./target/scala-2.10/*.jar`
SPARK_JAVA_OPTS=${SPARK_JAVA_OPTS-"-Dspark.executor.memory=$SPARK_EXECUTOR_MEMORY -cp $CLASSPATH"}
PYTHONSTARTUP=./sparklingpandas/shell.py PYTHON_PATH=`pwd`:$PTHYON_PATH $SPARK_HOME/bin/pyspark --jars $JARS --driver-class-path $JARS $@
