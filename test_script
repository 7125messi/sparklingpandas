#!/bin/bash
set -x
set -e
wget http://d3kbcqa49mib13.cloudfront.net/spark-1.4.1-bin-hadoop2.4.tgz &> /dev/null &
export WGET_PID=$!
sudo pip install --upgrade conda py4j
sudo conda init
deps='pip numpy pandas requests nose numpydoc sphinx pep8 pylint scipy openpyxl'
conda create -p $HOME/py --yes $deps "python=$TRAVIS_PYTHON_VERSION"
pip install unittest2
source activate /home/travis/py
export PATH=$HOME/py/bin:$PATH
echo "Our path is $PATH"
time pip install . &> install_logs &
INSTALL_PID=$!
./sbt/sbt assembly &> assembly &
ASSEMBLY_PID=$!
sudo apt-get update &> update_logs &
UPDATE_PID=$!
echo "waiting on update"
time wait $UPDATE_PID || echo "update finished before we got here"
sudo apt-get install liblapack-dev  libblas-dev  libblas3gf gfortran
export SPARK_HOME=./spark-1.4.1-bin-hadoop2.4/
export SPARK_CONF_DIR=./sparklingpandas/test/resources/conf
echo "waiting on spark download"
time wait $WGET_PID || echo "wget finished fast"
tar -xf spark-1.4.1-bin-hadoop2.4.tgz
tail -n 10 assembly
echo "waiting on assembly"
time wait $ASSEMBLY_PID || echo "assembly finished"
tail -n 10 assembly
nosetests --logging-level=ERROR --detailed-errors --verbosity=2 --with-coverage --cover-html-dir=./htmlcov --cover-package=sparklingpandas
pep8 --ignore=E402 sparklingpandas/
pylint -E sparklingpandas --extension-pkg-whitelist=numpy --disable=no-member
tail -n 15 install_logs
echo "waiting for install"
time waitpid $INSTALL_PID
tail -n 15 install_logs
export LOCATION=`pip show sparklingpandas|grep Location| cut -d ' ' -f 2`
echo "exit(0)" | $LOCATION/sparklingpandas/sparklingpandashell
