
===========
PandaSpark
===========

PandaSpark aims to make it easy to use the distributed computing power of PySpark to scale your data anlysis with Pandas.

Build status is at https://travis-ci.org/holdenk/pandaspark.svg?branch=master

Documentation
=========

None (right now). You can find some slides in the slides/ directory

Requirements
=========

The primary requirement of PandaSpark is that you have a recent (v1.0-SNAPSHOT currently) version of Spark installed - <http://spark.apache.org>

Using
=========

Make sure you have the SPARK_HOME enviroment variable set correctly, as PandaSpark uses this for including the PySpark libraries

Other than that you can install PandaSpark with pip and just import it. The primary unit of PandaSpark is a PRDD (Pandas Resillent Distributed Data Set)

State
=========

This is in early development and should not be considered usable.

Support
=========

There isn't really a mailing list, but if you want to use please feel free to e-mail me ( holden@pigscanfly.ca ) with any questions.
